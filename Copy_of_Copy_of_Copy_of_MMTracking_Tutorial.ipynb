{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arverges/mmtracking/blob/master/Copy_of_Copy_of_Copy_of_MMTracking_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9d79da1-6001-4f97-8381-b11b5516e640",
      "metadata": {
        "id": "a9d79da1-6001-4f97-8381-b11b5516e640",
        "tags": []
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/open-mmlab/mmtracking/blob/master/demo/MMTracking_Tutorial.ipynb)\n",
        "\n",
        "# **Welcome to MMTracking**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "527a563a-c8b2-44f0-ae20-0d226ab1e547",
      "metadata": {
        "id": "527a563a-c8b2-44f0-ae20-0d226ab1e547"
      },
      "source": [
        "In this tutorial, you will learn to:\n",
        "+ Install MMTracking.\n",
        "+ Perform inference with pretrained weights in MMTracking.\n",
        "+ Train a new MOT model with a toy dataset.\n",
        "Let's start!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab2c382c-a169-46fe-938f-c6687d763e8e",
      "metadata": {
        "id": "ab2c382c-a169-46fe-938f-c6687d763e8e"
      },
      "source": [
        "## **Install MMTracking**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8ced8f4-b07b-4216-8953-f7af6928b77c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8ced8f4-b07b-4216-8953-f7af6928b77c",
        "outputId": "b6d1f987-c36d-4d47-bd8f-677279887d14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchvision==0.10.0"
      ],
      "metadata": {
        "id": "VUp2cwkKSTKf",
        "outputId": "1c47990c-5726-4f10-e6d1-64f7dba52829",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VUp2cwkKSTKf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchvision==0.10.0\n",
            "  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (7.1.2)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchvision==0.10.0) (4.1.1)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchvision-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch"
      ],
      "metadata": {
        "id": "YDO_103BSTuL",
        "outputId": "4f5b5292-1cd5-441e-e0bb-e85f7f1bd9f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YDO_103BSTuL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 1.9.0\n",
            "Uninstalling torch-1.9.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/lib/python3.7/dist-packages/caffe2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torch-1.9.0.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torch-1.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -f https://download.pytorch.org/whl/cu111/torch_stable.html torch==1.9.0+cu111"
      ],
      "metadata": {
        "id": "u45j9G8uScnT",
        "outputId": "81dfb800-f85e-4991-971b-9f67675fe69e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "u45j9G8uScnT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/cu111/torch_stable.html\n",
            "Collecting torch==1.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2041.3 MB)\n",
            "\u001b[K     |█████████████                   | 834.1 MB 1.3 MB/s eta 0:15:23tcmalloc: large alloc 1147494400 bytes == 0x660fe000 @  0x7fcc660a9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 77.2 MB/s eta 0:00:13tcmalloc: large alloc 1434370048 bytes == 0x3926000 @  0x7fcc660a9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 4.0 MB/s eta 0:02:56tcmalloc: large alloc 1792966656 bytes == 0x59112000 @  0x7fcc660a9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.2 MB/s eta 0:04:50tcmalloc: large alloc 2241208320 bytes == 0xc3efa000 @  0x7fcc660a9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 1.3 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0x3926000 @  0x7fcc660a81e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n",
            "tcmalloc: large alloc 2551685120 bytes == 0x14985c000 @  0x7fcc660a9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 7.4 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu111) (4.1.1)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OUVugMrSWxB",
        "outputId": "1ce43455-8544-44fd-d330-0c9b7c22cf56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'mmtracking': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "%rm -r mmtracking"
      ],
      "id": "3OUVugMrSWxB"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "JcPsXqcsSgOZ",
        "outputId": "2456790c-ce50-4fe5-b351-2a235dc1a5d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JcPsXqcsSgOZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall mmcv-full\n",
        "!pip uninstall mmdet"
      ],
      "metadata": {
        "id": "_vxwoTvISld7",
        "outputId": "0dde32b6-ef49-4c74-e476-85d6d45d07ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_vxwoTvISld7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping mmcv-full as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping mmdet as it is not installed.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b4f093f-e197-42bd-ba64-dc905e379382",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b4f093f-e197-42bd-ba64-dc905e379382",
        "outputId": "2b102a4e-14b2-44e1-9441-53046ac19adc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
            "Collecting mmcv-full\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/mmcv_full-1.6.1-cp37-cp37m-manylinux1_x86_64.whl (46.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 46.9 MB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (21.3)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (6.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (4.6.0.66)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (1.21.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full) (3.0.9)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.6.1 yapf-0.32.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mmdet\n",
            "  Downloading mmdet-2.25.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet) (1.15.0)\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet) (1.21.6)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet) (2.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmdet) (4.1.1)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "Successfully installed mmdet-2.25.1 terminaltables-3.1.10\n",
            "Cloning into 'mmtracking'...\n",
            "remote: Enumerating objects: 7848, done.\u001b[K\n",
            "remote: Counting objects: 100% (318/318), done.\u001b[K\n",
            "remote: Compressing objects: 100% (188/188), done.\u001b[K\n",
            "remote: Total 7848 (delta 138), reused 285 (delta 125), pack-reused 7530\u001b[K\n",
            "Receiving objects: 100% (7848/7848), 2.75 MiB | 14.91 MiB/s, done.\n",
            "Resolving deltas: 100% (4995/4995), done.\n",
            "/content/mmtracking\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements/build.txt (line 1)) (0.29.32)\n",
            "Collecting numba==0.53.0\n",
            "  Downloading numba-0.53.0-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements/build.txt (line 3)) (1.21.6)\n",
            "Collecting llvmlite<0.37,>=0.36.0rc1\n",
            "  Downloading llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 657 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.53.0->-r requirements/build.txt (line 2)) (57.4.0)\n",
            "Installing collected packages: llvmlite, numba\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.0\n",
            "    Uninstalling llvmlite-0.39.0:\n",
            "      Successfully uninstalled llvmlite-0.39.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.0\n",
            "    Uninstalling numba-0.56.0:\n",
            "      Successfully uninstalled numba-0.56.0\n",
            "Successfully installed llvmlite-0.36.0 numba-0.53.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/mmtracking\n",
            "Collecting attributee==0.1.5\n",
            "  Downloading attributee-0.1.5.tar.gz (11 kB)\n",
            "Collecting dotty_dict\n",
            "  Downloading dotty_dict-1.3.1-py3-none-any.whl (7.0 kB)\n",
            "Collecting lap\n",
            "  Downloading lap-0.4.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (3.2.2)\n",
            "Collecting mmcls<1.0.0,>=0.16.0\n",
            "  Downloading mmcls-0.23.2-py2.py3-none-any.whl (578 kB)\n",
            "\u001b[K     |████████████████████████████████| 578 kB 56.1 MB/s \n",
            "\u001b[?25hCollecting motmetrics\n",
            "  Downloading motmetrics-1.2.5-py3-none-any.whl (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 66.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (21.3)\n",
            "Requirement already satisfied: pandas<=1.3.5 in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (1.3.5)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (2.0.4)\n",
            "Requirement already satisfied: scipy<=1.7.3 in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (1.7.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (0.11.2)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (3.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mmtrack==0.13.0) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcls<1.0.0,>=0.16.0->mmtrack==0.13.0) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.5->mmtrack==0.13.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.5->mmtrack==0.13.0) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas<=1.3.5->mmtrack==0.13.0) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmtrack==0.13.0) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmtrack==0.13.0) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmtrack==0.13.0) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmtrack==0.13.0) (4.1.1)\n",
            "Collecting xmltodict>=0.12.0\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: attributee, lap\n",
            "  Building wheel for attributee (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for attributee: filename=attributee-0.1.5-py3-none-any.whl size=12076 sha256=c89a19c60481e8e585db197c2733e3f04e3867d7a3c330bea6447ac580c3640f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/12/3a/b7e98eb4e3d373862bf9f160f77171b72a3825c4867064d8b2\n",
            "  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lap: filename=lap-0.4.0-cp37-cp37m-linux_x86_64.whl size=1590202 sha256=2924ea87d195cf1e0b32ba150912ea2cb221bb1d47ac8852f461e472496c229d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/0b/e3/ef9daf1b5547b56389e42c80c3100f1e6479bf5fd00fd9d6ba\n",
            "Successfully built attributee lap\n",
            "Installing collected packages: xmltodict, motmetrics, mmcls, lap, dotty-dict, attributee, mmtrack\n",
            "  Running setup.py develop for mmtrack\n",
            "Successfully installed attributee-0.1.5 dotty-dict-1.3.1 lap-0.4.0 mmcls-0.23.2 mmtrack-0.13.0 motmetrics-1.2.5 xmltodict-0.13.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/JonathonLuiten/TrackEval.git\n",
            "  Cloning https://github.com/JonathonLuiten/TrackEval.git to /tmp/pip-req-build-zjkmpgi5\n",
            "  Running command git clone -q https://github.com/JonathonLuiten/TrackEval.git /tmp/pip-req-build-zjkmpgi5\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from trackeval==1.0.dev1) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from trackeval==1.0.dev1) (1.7.3)\n",
            "Building wheels for collected packages: trackeval\n",
            "  Building wheel for trackeval (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trackeval: filename=trackeval-1.0.dev1-py3-none-any.whl size=121499 sha256=377bd18acce877b86e88e2dde49874caacea2406332bac86a7095872787eead6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8f7psoku/wheels/f3/ca/38/409a5a8b4faf77d7e99a90462e20a4723c5b0f20fa12364aa7\n",
            "Successfully built trackeval\n",
            "Installing collected packages: trackeval\n",
            "Successfully installed trackeval-1.0.dev1\n"
          ]
        }
      ],
      "source": [
        "# install MMCV\n",
        "!pip install --upgrade mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
        "\n",
        "# install MMDetection\n",
        "!pip install mmdet\n",
        "\n",
        "# clone the MMTracking repository\n",
        "!git clone https://github.com/open-mmlab/mmtracking.git\n",
        "%cd mmtracking\n",
        "\n",
        "# install MMTracking and its dependencies\n",
        "!pip install -r requirements/build.txt\n",
        "!pip install -e .\n",
        "# used to MOT evaluation\n",
        "!pip install git+https://github.com/JonathonLuiten/TrackEval.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03a4a583-78e7-40a1-a6ef-d80056989546",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03a4a583-78e7-40a1-a6ef-d80056989546",
        "outputId": "f31df450-ee92-4ec7-a91b-51a3ea2c6b23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sys.platform': 'linux',\n",
              " 'Python': '3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]',\n",
              " 'CUDA available': True,\n",
              " 'GPU 0': 'Tesla T4',\n",
              " 'CUDA_HOME': '/usr/local/cuda',\n",
              " 'NVCC': 'Cuda compilation tools, release 11.1, V11.1.105',\n",
              " 'GCC': 'x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0',\n",
              " 'PyTorch': '1.9.0+cu111',\n",
              " 'PyTorch compiling details': 'PyTorch built with:\\n  - GCC 7.3\\n  - C++ Version: 201402\\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\\n  - NNPACK is enabled\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 11.1\\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\\n  - CuDNN 8.0.5\\n  - Magma 2.5.2\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \\n',\n",
              " 'TorchVision': '0.10.0+cu102',\n",
              " 'OpenCV': '4.6.0',\n",
              " 'MMCV': '1.6.1',\n",
              " 'MMCV Compiler': 'GCC 7.3',\n",
              " 'MMCV CUDA Compiler': '11.1'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from mmcv import collect_env\n",
        "collect_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff6aea79-2ce9-4b1c-b3c4-3f92d1a4e34c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff6aea79-2ce9-4b1c-b3c4-3f92d1a4e34c",
        "outputId": "889e55a6-045d-4cb5-e802-fd529212ec12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0+cu111 True\n",
            "11.1\n",
            "GCC 7.3\n",
            "2.25.1\n",
            "0.13.0\n"
          ]
        }
      ],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check MMTracking installation\n",
        "import mmtrack\n",
        "print(mmtrack.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d43b49c-320a-4b0f-baca-fb4bde0630ff",
      "metadata": {
        "id": "4d43b49c-320a-4b0f-baca-fb4bde0630ff",
        "tags": []
      },
      "source": [
        "## **Perform inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd7c8466-f057-455f-985a-71e5f22c36e4",
      "metadata": {
        "id": "dd7c8466-f057-455f-985a-71e5f22c36e4"
      },
      "outputs": [],
      "source": [
        "# unset the proxy for downloading the pretrained models (optional)\n",
        "!unset https_proxy\n",
        "!unset http_proxy\n",
        "\n",
        "# download checkpoints\n",
        "!mkdir checkpoints\n",
        "#!wget -c https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r50_dc5_1x_imagenetvid/selsa_faster_rcnn_r50_dc5_1x_imagenetvid_20201227_204835-2f5a4952.pth -P ./checkpoints\n",
        "#!wget -c https://download.openmmlab.com/mmtracking/sot/siamese_rpn/siamese_rpn_r50_1x_lasot/siamese_rpn_r50_1x_lasot_20211203_151612-da4b3c66.pth -P ./checkpoints\n",
        "#!wget -c https://download.openmmlab.com/mmtracking/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth -P ./checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "420dae4b-4426-405e-97fb-7823943b8ee8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "420dae4b-4426-405e-97fb-7823943b8ee8",
        "outputId": "d359b621-ac9f-4f43-f26e-6e3c1f81d160"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-102c801476dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmmcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmmtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minference_mot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmot_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./configs/mot/deepsort/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minput_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./demo/demo.mp4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmtracking/mmtrack/apis/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) OpenMMLab. All rights reserved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minference_mot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_sot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_vid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmulti_gpu_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_gpu_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_random_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mmtracking/mmtrack/apis/inference.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmmdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmtrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmdet/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) OpenMMLab. All rights reserved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDATASETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIPELINES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcityscapes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCityscapesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCocoDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcoco_panoptic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCocoPanopticDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmdet/datasets/cityscapes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDATASETS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCocoDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmdet/datasets/coco.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi_wrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOCOeval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDATASETS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcustom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmdet/datasets/custom.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meval_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_recalls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDATASETS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmdet/datasets/pipelines/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                       LoadPanopticAnnotations, LoadProposals)\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtest_time_aug\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleFlipAug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from .transforms import (Albu, CopyPaste, CutOut, Expand, MinIoURandomCrop,\n\u001b[0m\u001b[1;32m     14\u001b[0m                          \u001b[0mMixUp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMosaic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPhotoMetricDistortion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                          \u001b[0mRandomAffine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomCenterCropPad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomCrop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mmdet/datasets/pipelines/transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0malbumentations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0malbumentations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/albumentations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# imgaug is not installed by default, so we import stubs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/albumentations/imgaug/transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mimgaug\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     raise ImportError(\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"You are trying to import an augmentation that depends on the imgaug library, but imgaug is not installed. To \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imgaug/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgaug\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentables\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maugmentables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentables\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmenters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maugmenters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imgaug/augmentables/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmaps\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegmaps\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imgaug/augmentables/segmaps.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimgaug\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmenters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mblend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mblendlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIAugmentable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imgaug/augmenters/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmenters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpillike\u001b[0m  \u001b[0;31m# use via: iaa.pillike.*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmenters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmenters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegmentation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmenters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimgaug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmenters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweather\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imgaug/augmenters/segmentation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# because otherwise unittest seems to mix up imgaug.augmenters.segmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# with skimage.segmentation for whatever reason\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/segmentation/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_expand_labels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexpand_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrandom_walker_segmentation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom_walker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mactive_contour_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactive_contour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_felzenszwalb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfelzenszwalb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mslic_superpixels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mslic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/segmentation/active_contour_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRectBivariateSpline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_as_float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msobel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/filters/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                            \u001b[0mthreshold_multiotsu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_all_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                            apply_hysteresis_threshold)\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mridges\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmeijering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msato\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrangi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhessian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_median\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmedian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/filters/ridges.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimg_as_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_nD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhessian_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhessian_matrix_eigvals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/feature/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_canny\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcanny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_cascade\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCascade\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_daisy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdaisy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_hog\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# run mot demo\n",
        "import mmcv\n",
        "import tempfile\n",
        "from mmtrack.apis import inference_mot, init_model\n",
        "mot_config = './configs/mot/deepsort/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py'\n",
        "input_video = './demo/demo.mp4'\n",
        "imgs = mmcv.VideoReader(input_video)\n",
        "# build the model from a config file\n",
        "mot_model = init_model(mot_config, device='cuda:0')\n",
        "prog_bar = mmcv.ProgressBar(len(imgs))\n",
        "out_dir = tempfile.TemporaryDirectory()\n",
        "out_path = out_dir.name\n",
        "# test and show/save the images\n",
        "for i, img in enumerate(imgs):\n",
        "    result = inference_mot(mot_model, img, frame_id=i)\n",
        "    mot_model.show_result(\n",
        "            img,\n",
        "            result,\n",
        "            show=False,\n",
        "            wait_time=int(1000. / imgs.fps),\n",
        "            out_file=f'{out_path}/{i:06d}.jpg')\n",
        "    prog_bar.update()\n",
        "\n",
        "output = './demo/mot.mp4'\n",
        "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
        "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
        "out_dir.cleanup()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u6k1lLV-u2R",
        "outputId": "ec26c027-7596-4b0a-f77e-2b235f3058d1"
      },
      "id": "2u6k1lLV-u2R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a91a55bd-14be-46bf-aa18-5e30d9abe5b7",
      "metadata": {
        "id": "a91a55bd-14be-46bf-aa18-5e30d9abe5b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f893d65-11ea-420d-ad44-93b96c7ebd36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os.path, zipfile, os, re, time \n",
        "from tqdm import tqdm\n",
        "from datetime import timedelta\n",
        "time_start = time.time()\n",
        "\n",
        "!mkdir data\n",
        "gdrive_path = '/content/drive/MyDrive/Colab_Notebooks/LaSOT_category'\n",
        "local_path = '/content/mmtracking/data'\n",
        "os.path.exists('/content/drive/MyDrive/Colab_Notebooks/LaSOT_category/airplane.zip')\n",
        "dnc_dirs = ['airplane', 'basketball', 'bear', 'bicycle', 'bird', 'boat', 'book', 'bottle', 'bus', 'car','cat', 'cattle', 'chameleon', 'coin', 'crab', 'crocodile', 'cup', 'deer', 'dog', 'drone', 'electricfan', 'elephant', 'flag', 'fox', 'frog', 'gametarget', 'gecko', 'giraffe', 'goldfish', 'gorilla', 'guitar', 'hand', 'hat', 'helmet', 'hippo', 'horse', 'kangaroo', 'kite', 'leopard', 'licenseplate', 'lion', 'lizard','microphone', 'monkey', 'motorcycle', 'mouse', 'person', 'pig', 'rabbit','racing', 'robot', 'rubicCube', 'sepia', 'shark', 'sheep', 'skateboard', 'spider', 'squirrel', 'surfboard', 'swing', 'tank', 'tiger', 'train', 'truck', 'turtle', 'umbrella', 'volleyball', 'yoyo', 'zebra']\n",
        "local_t, local_v, local_ts = [os.path.join(local_path,d) for d in dnc_dirs]\n",
        "for d in os.listdir(gdrive_path):\n",
        "  if d not in dnc_dirs and not d.endswith('.zip'):\n",
        "    os.system(f'ln -s \\\"{os.path.join(gdrive_path, d)}\\\" {local_path}')\n",
        "\n",
        "ap = 'airplanxe.zip'\n",
        "ba = 'basketball.zip'\n",
        "bear = 'bear.zip'\n",
        "bi = 'bicycle.zip'\n",
        "bird = 'bitd.zip'\n",
        "boat = 'boat.zip'\n",
        "book = 'book.zip'\n",
        "bot = 'bottle.zip'\n",
        "bus = 'bus.zip'\n",
        "car = 'car.zip'\n",
        "cat = 'cat.zip'\n",
        "catt = 'cattle.zip'\n",
        "cham = 'chameleon.zip'\n",
        "co = 'coin.zip'\n",
        "cr = 'crab.zip'\n",
        "cro = 'crocodile.zip'\n",
        "cup = 'cup.zip'\n",
        "de = 'deer.zip'\n",
        "dog = 'dog.zip'\n",
        "dr = 'drone.zip'\n",
        "e = 'electricfan.zip'\n",
        "el = 'elephant.zip'\n",
        "fl = 'flag.zip'\n",
        "fox = 'fox.zip'\n",
        "fr = 'frog.zip'\n",
        "g = 'gametarget.zip'\n",
        "ge = 'gecko.zip'\n",
        "gi = 'giraffe.zip'\n",
        "gold = 'goldfish.zip'\n",
        "gor = 'gorilla.zip'\n",
        "gu = 'guitar.zip'\n",
        "h = 'hand.zip'\n",
        "hat = 'hat.zip'\n",
        "he = 'helmet.zip'\n",
        "hi = 'hippo.zip'\n",
        "ho = 'horse.zip'\n",
        "kan = 'kangaroo.zip'\n",
        "ki = 'kite.zip'\n",
        "le = 'leopard.zip'\n",
        "l = 'licenseplate.zip'\n",
        "li = 'lion.zip'\n",
        "liz = 'lizard.zip'\n",
        "micro = 'microphone.zip'\n",
        "mon = 'monkey.zip'\n",
        "mou = 'mouse.zip'\n",
        "motor = 'motorcycle.zip'\n",
        "p = 'person.zip'\n",
        "pig = 'pig.zip'\n",
        "ra = 'rabbit.zip'\n",
        "rac = 'racing.zip'\n",
        "ro = 'robot.zip'\n",
        "ru = 'rubicCube.zip'\n",
        "s = 'sepia.zip'\n",
        "sha = 'shark.zip'\n",
        "she = 'sheep.zip'\n",
        "ska = 'skateboard.zip'\n",
        "spi = 'spider.zip'\n",
        "squ = 'squirrel.zip'\n",
        "sur = 'surfboard.zip'\n",
        "swi = 'swing.zip'\n",
        "tan = 'tank.zip'\n",
        "ti = 'tiger.zip'\n",
        "tra = 'train.zip'\n",
        "tru = 'truck.zip'\n",
        "tur = 'turtle.zip'\n",
        "umb = 'umbrella.zip'\n",
        "vol = 'volleyball.zip'\n",
        "yo = 'yoyo.zip'\n",
        "zeb = 'zebra.zip'\n",
        "\n",
        "ap_zip = os.path.join(gdrive,ap)\n",
        "ba_zip = os.path.join(gdrive,ba)\n",
        "bear_zip = os.path.join(gdrive,bear)\n",
        "bi_zip = os.path.join(gdrive,bi)\n",
        "bird_zip = os.path.join(gdrive,bird)\n",
        "book_zip = os.path.join(gdrive,book)\n",
        "boat_zip = os.path.join(gdrive,boat)\n",
        "bot_zip = os.path.join(gdrive, bot)\n",
        "bus_zip = os.path.join(gdrive, bus)\n",
        "car_zip = os.path.join(gdrive, car)\n",
        "cat_zip = os.path.join(gdrive,cat)\n",
        "catt_zip = os,path.join(gdrive,catt)\n",
        "cham_zip = os.path.join(gdrive, cham)\n",
        "co_zip = os.path.join(gdrive,co)\n",
        "cr_zip = os.path.join(gdrive, cr)\n",
        "cro_zip = os.path.join(gdrive, cro)\n",
        "cup_zip = os.path.join(gdrive, cup)\n",
        "de_zip = os.path.join(gdrive, de)\n",
        "dog_zip = os.path.join(gdrive, dog)\n",
        "dr_zip = os.path.join(gdrive, dr)\n",
        "e_zip = os.path.join(gdrive,e)\n",
        "el_zip = os.path.join(gdrive,el) \n",
        "fl_zip = os.path.join(gdrive, fl)\n",
        "fox_zip = os.path.join(gdrive, fox)\n",
        "fr_zip = os.path.join(gdrive, fr)\n",
        "g_zip = os.path.join(gdrive,g)\n",
        "ge_zip = os.path.join(gdrive, ge),\n",
        "gi_zip = os.path.join(gdrive, gi)\n",
        "gold_zip = os.path.join(gdrive, gold)\n",
        "gor_zip = os.path.join(gdrive, gor)\n",
        "gu_zip = os.path.join(gdrive, gu)\n",
        "h_zip = os.path.join(gdrive, h)\n",
        "hat_zip = os.path.join(gdrive, hat)\n",
        "he_zip = os.path.join(gdrive, he)\n",
        "hi_zip = os.path.join(gdrive, hi)\n",
        "ho_zip = os.path.join(gdrive,ho)\n",
        "kan_zip = os.path.join(gdrive, kan)\n",
        "ki_zip = os.path.join(gdrive, ki)\n",
        "le_zip = os.path.join(gdrive, le)\n",
        "l_zip = os.path.join(gdrive,l)\n",
        "li_zip = os.path.join(gdrive, li)\n",
        "liz_zip = os.path.join(gdrive, liz)\n",
        "micro_zip = os.path.join(gdrive, micro)\n",
        "mon_zip = os.path.join(gdrive,mon)\n",
        "mou_zip = os.path.join(gdrive,mou)\n",
        "motor_zip = os.path.join(gdrive,motor)\n",
        "p_zip = os.path.join(gdrive,p)\n",
        "pig_zip = os.path.join(gdrive,pig)\n",
        "ra_zip = os.path.join(gdrive,ra)\n",
        "rac_zip = os.path(gdrive,rac)\n",
        "ro_zip = os.path.join(gdrive,ro)\n",
        "ru_zip = os.path.join(gdrive,ru)\n",
        "s_zip = os.path.join(gdrive,s)\n",
        "sha_zip = os.path.join(gdrive,sha)\n",
        "she_zip = os.path.join(gdrive,she)\n",
        "ska_zip = os.path.join(gdrive, ska)\n",
        "spi_zip = os.path.join(gdrive, spi)\n",
        "squ_zip = os.path.join(gdrive, squ)\n",
        "sur_zip = os.path.join(gdrive, sur)\n",
        "swi_zip = os.path.join(gdrive,swi)\n",
        "tan_zip = os.path.join(gdrive, tan)\n",
        "ti_zip = os.path.join(gdrive, ti)\n",
        "tra_zip = os.path.join(gdrive, tra)\n",
        "tru_zip = os.path.join(gdrive, tru)\n",
        "tur_zip = os.path.join(gdrive, tur)\n",
        "umb_zip = os.path.join(gdrive, umb)\n",
        "vol_zip = os.path.join(gdrive, vol)\n",
        "yo_zip = os.path.join(gdrive, yo)\n",
        "zeb_zip = os.path.join(gdrive, zeb)\n",
        "\n",
        "#os.path.exists(\"/content/drive/MyDrive/Colab_Notebooks/LaSOTBenchmark.zip\")\n",
        "#zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/Colab_Notebooks/LaSOTBenchmark.zip\", 'r')\n",
        "#zip_ref.extractall(\"/content/mmtracking/data\")\n",
        "#zip_ref.close() \n",
        "#!wget https://drive.google.com/drive/folders/1v09JELSXM_v7u3dF7akuqqkVG8T1EK2_ -P ./data\n",
        "#!wget https://download.openmmlab.com/mmtracking/data/MOT17_tiny.zip -P ./data\n",
        "#!unzip -q ./data/MOT17_tiny.zip -d ./data\n",
        "#!unzip -q ./data/LaSOTBenchmark.zip -d ./data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0189f86a-b216-4f63-a58a-97e40e326869",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0189f86a-b216-4f63-a58a-97e40e326869",
        "outputId": "33a6cfac-1db2-438d-d02f-9a64c4b69593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mmcv/cnn/bricks/conv_module.py:154: UserWarning: Unnecessary conv bias before batch/instance norm\n",
            "  'Unnecessary conv bias before batch/instance norm')\n",
            "2022-07-30 16:04:30,337 - mmtrack - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
            "2022-07-30 16:04:30,342 - mmcv - INFO - load model from: torchvision://resnet50\n",
            "2022-07-30 16:04:30,344 - mmcv - INFO - load checkpoint from torchvision path: torchvision://resnet50\n",
            "2022-07-30 16:04:30,418 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: layer4.0.conv1.weight, layer4.0.bn1.running_mean, layer4.0.bn1.running_var, layer4.0.bn1.weight, layer4.0.bn1.bias, layer4.0.conv2.weight, layer4.0.bn2.running_mean, layer4.0.bn2.running_var, layer4.0.bn2.weight, layer4.0.bn2.bias, layer4.0.conv3.weight, layer4.0.bn3.running_mean, layer4.0.bn3.running_var, layer4.0.bn3.weight, layer4.0.bn3.bias, layer4.0.downsample.0.weight, layer4.0.downsample.1.running_mean, layer4.0.downsample.1.running_var, layer4.0.downsample.1.weight, layer4.0.downsample.1.bias, layer4.1.conv1.weight, layer4.1.bn1.running_mean, layer4.1.bn1.running_var, layer4.1.bn1.weight, layer4.1.bn1.bias, layer4.1.conv2.weight, layer4.1.bn2.running_mean, layer4.1.bn2.running_var, layer4.1.bn2.weight, layer4.1.bn2.bias, layer4.1.conv3.weight, layer4.1.bn3.running_mean, layer4.1.bn3.running_var, layer4.1.bn3.weight, layer4.1.bn3.bias, layer4.2.conv1.weight, layer4.2.bn1.running_mean, layer4.2.bn1.running_var, layer4.2.bn1.weight, layer4.2.bn1.bias, layer4.2.conv2.weight, layer4.2.bn2.running_mean, layer4.2.bn2.running_var, layer4.2.bn2.weight, layer4.2.bn2.bias, layer4.2.conv3.weight, layer4.2.bn3.running_mean, layer4.2.bn3.running_var, layer4.2.bn3.weight, layer4.2.bn3.bias, fc.weight, fc.bias\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load checkpoint from local path: /content/checkpoints/stark_st1_r50_500e_lasot_20220414_185654-9c19e39e.pth\n",
            "[>>>>                               ] 1/8, 1.8 task/s, elapsed: 1s, ETA:     4s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 5.3 task/s, elapsed: 2s, ETA:     0s\n",
            " making the output video at ./demo/sot.mp4 with a FPS of 3.0\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 21.8 task/s, elapsed: 0s, ETA:     0s\n"
          ]
        }
      ],
      "source": [
        "# run sot demo\n",
        "from mmtrack.apis import inference_sot, init_model\n",
        "import os.path\n",
        "import mmcv\n",
        "import tempfile\n",
        "sot_config = './configs/sot/stark/stark_st1_r50_500e_lasot.py'\n",
        "sot_checkpoint = '/content/checkpoints/stark_st1_r50_500e_lasot_20220414_185654-9c19e39e.pth'\n",
        "input_video = './demo/demo.mp4'\n",
        "# build the model from a config file and a checkpoint file\n",
        "sot_model = init_model(sot_config, sot_checkpoint, device='cuda:0')\n",
        "init_bbox = [371, 411, 450, 646]\n",
        "# images = mmcv.imread(#path_to_dataset)\n",
        "imgs = mmcv.VideoReader(input_video)\n",
        "prog_bar = mmcv.ProgressBar(len(imgs))\n",
        "out_dir = tempfile.TemporaryDirectory()\n",
        "out_path = out_dir.name\n",
        "for i, img in enumerate(imgs):\n",
        "    result = inference_sot(sot_model, img, init_bbox, frame_id=i)\n",
        "    sot_model.show_result(\n",
        "            img,\n",
        "            result,\n",
        "            wait_time=int(1000. / imgs.fps),\n",
        "            out_file=f'{out_path}/{i:06d}.jpg')\n",
        "    prog_bar.update()\n",
        "output = './demo/sot.mp4'\n",
        "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
        "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
        "out_dir.cleanup()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "500ff07b-9664-4429-9e3f-e97dd4fa1c29",
      "metadata": {
        "id": "500ff07b-9664-4429-9e3f-e97dd4fa1c29",
        "tags": []
      },
      "source": [
        "## **Train a MOT model with a toy dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7bd4f44-447a-49a5-8c9c-cf160691bda5",
      "metadata": {
        "id": "e7bd4f44-447a-49a5-8c9c-cf160691bda5",
        "tags": []
      },
      "source": [
        "### **Prepare dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0db0d5f-b192-48ee-b145-149f33ad3685",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0db0d5f-b192-48ee-b145-149f33ad3685",
        "outputId": "862387e7-0e07-42f0-a199-fd242311dbe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting train set to COCO format\n",
            "100% 2/2 [00:00<00:00,  2.58it/s]\n",
            "train has 145 instances.\n",
            "Done! Saved as ./data/MOT17_tiny/annotations/train_cocoformat.json and ./data/MOT17_tiny/annotations/train_detections.pkl\n",
            "Converting test set to COCO format\n",
            "0it [00:00, ?it/s]\n",
            "test has 0 instances.\n",
            "Done! Saved as ./data/MOT17_tiny/annotations/test_cocoformat.json and ./data/MOT17_tiny/annotations/test_detections.pkl\n",
            "Converting half-train set to COCO format\n",
            "100% 2/2 [00:01<00:00,  1.15it/s]\n",
            "half-train has 104 instances.\n",
            "Done! Saved as ./data/MOT17_tiny/annotations/half-train_cocoformat.json and ./data/MOT17_tiny/annotations/half-train_detections.pkl\n",
            "Converting half-val set to COCO format\n",
            "100% 2/2 [00:01<00:00,  1.18it/s]\n",
            "half-val has 122 instances.\n",
            "Done! Saved as ./data/MOT17_tiny/annotations/half-val_cocoformat.json and ./data/MOT17_tiny/annotations/half-val_detections.pkl\n",
            "100% 2/2 [08:41<00:00, 260.86s/it]\n"
          ]
        }
      ],
      "source": [
        "# convert the dataset to coco format\n",
        "!python ./tools/convert_datasets/mot/mot2coco.py -i ./data/MOT17_tiny/ -o ./data/MOT17_tiny/annotations --split-train --convert-det\n",
        "# crop pedestrian patches from the original dataset for training reid model. It may take a few minutes.\n",
        "!rm -rf ./data/MOT17_tiny/reid\n",
        "!python ./tools/convert_datasets/mot/mot2reid.py -i ./data/MOT17_tiny/ -o ./data/MOT17_tiny/reid --val-split 0.9 --vis-threshold 0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae887970-7382-4bd0-a739-6b07e6dded6f",
      "metadata": {
        "id": "ae887970-7382-4bd0-a739-6b07e6dded6f",
        "tags": []
      },
      "source": [
        "### **Train a detector for MOT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bce04095-8586-45c5-a556-40c51d08b2cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bce04095-8586-45c5-a556-40c51d08b2cb",
        "outputId": "05f85750-c853-4887-c8e4-306401b866c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config:\n",
            "model = dict(\n",
            "    detector=dict(\n",
            "        type='FasterRCNN',\n",
            "        backbone=dict(\n",
            "            type='ResNet',\n",
            "            depth=50,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=True),\n",
            "            norm_eval=True,\n",
            "            style='pytorch',\n",
            "            init_cfg=dict(\n",
            "                type='Pretrained', checkpoint='torchvision://resnet50')),\n",
            "        neck=dict(\n",
            "            type='FPN',\n",
            "            in_channels=[256, 512, 1024, 2048],\n",
            "            out_channels=256,\n",
            "            num_outs=5),\n",
            "        rpn_head=dict(\n",
            "            type='RPNHead',\n",
            "            in_channels=256,\n",
            "            feat_channels=256,\n",
            "            anchor_generator=dict(\n",
            "                type='AnchorGenerator',\n",
            "                scales=[8],\n",
            "                ratios=[0.5, 1.0, 2.0],\n",
            "                strides=[4, 8, 16, 32, 64]),\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[1.0, 1.0, 1.0, 1.0],\n",
            "                clip_border=False),\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "            loss_bbox=dict(\n",
            "                type='SmoothL1Loss', beta=0.1111111111111111,\n",
            "                loss_weight=1.0)),\n",
            "        roi_head=dict(\n",
            "            type='StandardRoIHead',\n",
            "            bbox_roi_extractor=dict(\n",
            "                type='SingleRoIExtractor',\n",
            "                roi_layer=dict(\n",
            "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "                out_channels=256,\n",
            "                featmap_strides=[4, 8, 16, 32]),\n",
            "            bbox_head=dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=1,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.1, 0.1, 0.2, 0.2],\n",
            "                    clip_border=False),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', loss_weight=1.0))),\n",
            "        train_cfg=dict(\n",
            "            rpn=dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.7,\n",
            "                    neg_iou_thr=0.3,\n",
            "                    min_pos_iou=0.3,\n",
            "                    match_low_quality=True,\n",
            "                    ignore_iof_thr=-1),\n",
            "                sampler=dict(\n",
            "                    type='RandomSampler',\n",
            "                    num=256,\n",
            "                    pos_fraction=0.5,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=False),\n",
            "                allowed_border=-1,\n",
            "                pos_weight=-1,\n",
            "                debug=False),\n",
            "            rpn_proposal=dict(\n",
            "                nms_pre=2000,\n",
            "                max_per_img=1000,\n",
            "                nms=dict(type='nms', iou_threshold=0.7),\n",
            "                min_bbox_size=0),\n",
            "            rcnn=dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.5,\n",
            "                    neg_iou_thr=0.5,\n",
            "                    min_pos_iou=0.5,\n",
            "                    match_low_quality=False,\n",
            "                    ignore_iof_thr=-1),\n",
            "                sampler=dict(\n",
            "                    type='RandomSampler',\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=True),\n",
            "                pos_weight=-1,\n",
            "                debug=False)),\n",
            "        test_cfg=dict(\n",
            "            rpn=dict(\n",
            "                nms_pre=1000,\n",
            "                max_per_img=1000,\n",
            "                nms=dict(type='nms', iou_threshold=0.7),\n",
            "                min_bbox_size=0),\n",
            "            rcnn=dict(\n",
            "                score_thr=0.05,\n",
            "                nms=dict(type='nms', iou_threshold=0.5),\n",
            "                max_per_img=100)),\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained',\n",
            "            checkpoint=\n",
            "            'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'\n",
            "        )))\n",
            "dataset_type = 'CocoDataset'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile', to_float32=True),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        type='Resize',\n",
            "        img_scale=(1088, 1088),\n",
            "        ratio_range=(0.8, 1.2),\n",
            "        keep_ratio=True,\n",
            "        bbox_clip_border=False),\n",
            "    dict(type='PhotoMetricDistortion'),\n",
            "    dict(type='RandomCrop', crop_size=(1088, 1088), bbox_clip_border=False),\n",
            "    dict(type='RandomFlip', flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(1088, 1088),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=True),\n",
            "            dict(type='RandomFlip'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data_root = 'data/MOT17_tiny/'\n",
            "data = dict(\n",
            "    samples_per_gpu=2,\n",
            "    workers_per_gpu=2,\n",
            "    train=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='data/MOT17_tiny/annotations/half-train_cocoformat.json',\n",
            "        img_prefix='data/MOT17_tiny/train',\n",
            "        classes=('pedestrian', ),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile', to_float32=True),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                type='Resize',\n",
            "                img_scale=(1088, 1088),\n",
            "                ratio_range=(0.8, 1.2),\n",
            "                keep_ratio=True,\n",
            "                bbox_clip_border=False),\n",
            "            dict(type='PhotoMetricDistortion'),\n",
            "            dict(\n",
            "                type='RandomCrop',\n",
            "                crop_size=(1088, 1088),\n",
            "                bbox_clip_border=False),\n",
            "            dict(type='RandomFlip', flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
            "        img_prefix='data/MOT17_tiny/train',\n",
            "        classes=('pedestrian', ),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1088, 1088),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CocoDataset',\n",
            "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
            "        img_prefix='data/MOT17_tiny/train',\n",
            "        classes=('pedestrian', ),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1088, 1088),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "evaluation = dict(metric=['bbox'])\n",
            "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=None)\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "opencv_num_threads = 0\n",
            "mp_start_method = 'fork'\n",
            "USE_MMDET = True\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=100,\n",
            "    warmup_ratio=0.01,\n",
            "    step=[3])\n",
            "total_epochs = 4\n",
            "work_dir = './tutorial_exps/detector'\n",
            "seed = 0\n",
            "gpu_ids = range(0, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import mmcv\n",
        "from mmdet.apis import set_random_seed\n",
        "cfg = mmcv.Config.fromfile('./configs/det/faster-rcnn_r50_fpn_4e_mot17-half.py')\n",
        "cfg.data_root = 'data/MOT17_tiny/'\n",
        "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.train.ann_file = cfg.data.train.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "\n",
        "cfg.data.test.img_prefix = cfg.data.test.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.train.img_prefix = cfg.data.train.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.val.img_prefix = cfg.data.val.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "\n",
        "cfg.work_dir = './tutorial_exps/detector'\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "889b4255-50be-4da3-85c4-dcd19c8111ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7f20458c3bf7422fba34beba519c27bd",
            "9e5d67b0f3fb4baaa7254a102464057b",
            "f750ac53345746ee8c0364b5f850a56d",
            "3ed731e3194e4465aa7b79579f8eaaca",
            "7a4444bb015249ae9caa2b14c21fa0fd",
            "9718af278d2d45e99d1355cafc2c7518",
            "cb11dac7ded84ad59f12a03b04660b3c",
            "f2613e8b5e1e453db11090a1aa888799",
            "9bdb4cdea53b429cad0e8c418fd7e715",
            "750088e53a064a13872ed5fa5616face",
            "eb8e5c96ffea40e298a38db2b5a38ace"
          ]
        },
        "id": "889b4255-50be-4da3-85c4-dcd19c8111ac",
        "outputId": "bcc096ba-5ce0-4eb3-ab81-776d54424104"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-04-20 05:00:52,752 - mmtrack - INFO - initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': 'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'}\n",
            "2022-04-20 05:00:52,754 - mmcv - INFO - load model from: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
            "2022-04-20 05:00:52,757 - mmcv - INFO - load checkpoint from http path: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
            "Downloading: \"http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\" to /root/.cache/torch/hub/checkpoints/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f20458c3bf7422fba34beba519c27bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/160M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-04-20 05:01:06,227 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).\n",
            "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\n",
            "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([4]).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mmdet/apis/train.py:135: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.\n",
            "  'please set `runner` in your config.', UserWarning)\n",
            "2022-04-20 05:01:06,593 - mmdet - INFO - Start running, host: root@597380361c27, work_dir: /content/mmtracking/tutorial_exps/detector\n",
            "2022-04-20 05:01:06,597 - mmdet - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(ABOVE_NORMAL) OptimizerHook                      \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_run:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "2022-04-20 05:01:06,598 - mmdet - INFO - workflow: [('train', 1)], max: 4 epochs\n",
            "2022-04-20 05:01:06,603 - mmdet - INFO - Checkpoints will be saved to /content/mmtracking/tutorial_exps/detector by HardDiskBackend.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done (t=0.24s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-04-20 05:01:31,165 - mmdet - INFO - Epoch [1][50/414]\tlr: 9.902e-03, eta: 0:13:04, time: 0.488, data_time: 0.057, memory: 4076, loss_rpn_cls: 0.0903, loss_rpn_bbox: 0.1182, loss_cls: 0.4110, acc: 80.7461, loss_bbox: 0.3526, loss: 0.9721\n",
            "2022-04-20 05:01:53,688 - mmdet - INFO - Epoch [1][100/414]\tlr: 1.980e-02, eta: 0:12:10, time: 0.450, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0428, loss_rpn_bbox: 0.1039, loss_cls: 0.3214, acc: 86.3828, loss_bbox: 0.2210, loss: 0.6892\n",
            "2022-04-20 05:02:16,652 - mmdet - INFO - Epoch [1][150/414]\tlr: 2.000e-02, eta: 0:11:41, time: 0.460, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0323, loss_rpn_bbox: 0.0995, loss_cls: 0.3064, acc: 86.8105, loss_bbox: 0.2305, loss: 0.6687\n",
            "2022-04-20 05:02:39,044 - mmdet - INFO - Epoch [1][200/414]\tlr: 2.000e-02, eta: 0:11:11, time: 0.448, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0250, loss_rpn_bbox: 0.0851, loss_cls: 0.2920, acc: 87.6348, loss_bbox: 0.2078, loss: 0.6100\n",
            "2022-04-20 05:03:01,524 - mmdet - INFO - Epoch [1][250/414]\tlr: 2.000e-02, eta: 0:10:45, time: 0.450, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0215, loss_rpn_bbox: 0.0885, loss_cls: 0.2655, acc: 88.7930, loss_bbox: 0.1828, loss: 0.5583\n",
            "2022-04-20 05:03:23,948 - mmdet - INFO - Epoch [1][300/414]\tlr: 2.000e-02, eta: 0:10:20, time: 0.448, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0183, loss_rpn_bbox: 0.0782, loss_cls: 0.2394, acc: 89.7695, loss_bbox: 0.1668, loss: 0.5026\n",
            "2022-04-20 05:03:46,433 - mmdet - INFO - Epoch [1][350/414]\tlr: 2.000e-02, eta: 0:09:55, time: 0.450, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0138, loss_rpn_bbox: 0.0567, loss_cls: 0.2319, acc: 89.9453, loss_bbox: 0.1573, loss: 0.4597\n",
            "2022-04-20 05:04:08,858 - mmdet - INFO - Epoch [1][400/414]\tlr: 2.000e-02, eta: 0:09:31, time: 0.449, data_time: 0.011, memory: 4076, loss_rpn_cls: 0.0162, loss_rpn_bbox: 0.0612, loss_cls: 0.2286, acc: 90.2344, loss_bbox: 0.1549, loss: 0.4609\n",
            "2022-04-20 05:04:14,853 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
            "2022-04-20 05:04:41,618 - mmdet - INFO - Epoch [2][50/414]\tlr: 2.000e-02, eta: 0:08:51, time: 0.494, data_time: 0.056, memory: 4076, loss_rpn_cls: 0.0112, loss_rpn_bbox: 0.0556, loss_cls: 0.2086, acc: 91.0938, loss_bbox: 0.1399, loss: 0.4153\n",
            "2022-04-20 05:05:04,096 - mmdet - INFO - Epoch [2][100/414]\tlr: 2.000e-02, eta: 0:08:29, time: 0.449, data_time: 0.009, memory: 4076, loss_rpn_cls: 0.0142, loss_rpn_bbox: 0.0651, loss_cls: 0.2114, acc: 91.0215, loss_bbox: 0.1455, loss: 0.4361\n",
            "2022-04-20 05:05:26,701 - mmdet - INFO - Epoch [2][150/414]\tlr: 2.000e-02, eta: 0:08:07, time: 0.452, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0134, loss_rpn_bbox: 0.0591, loss_cls: 0.2047, acc: 91.0449, loss_bbox: 0.1366, loss: 0.4139\n",
            "2022-04-20 05:05:49,108 - mmdet - INFO - Epoch [2][200/414]\tlr: 2.000e-02, eta: 0:07:45, time: 0.448, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0120, loss_rpn_bbox: 0.0558, loss_cls: 0.1954, acc: 91.4688, loss_bbox: 0.1318, loss: 0.3950\n",
            "2022-04-20 05:06:11,711 - mmdet - INFO - Epoch [2][250/414]\tlr: 2.000e-02, eta: 0:07:23, time: 0.452, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0103, loss_rpn_bbox: 0.0494, loss_cls: 0.1877, acc: 91.9941, loss_bbox: 0.1246, loss: 0.3719\n",
            "2022-04-20 05:06:34,057 - mmdet - INFO - Epoch [2][300/414]\tlr: 2.000e-02, eta: 0:07:01, time: 0.447, data_time: 0.009, memory: 4076, loss_rpn_cls: 0.0112, loss_rpn_bbox: 0.0543, loss_cls: 0.1757, acc: 92.4961, loss_bbox: 0.1208, loss: 0.3621\n",
            "2022-04-20 05:06:56,363 - mmdet - INFO - Epoch [2][350/414]\tlr: 2.000e-02, eta: 0:06:38, time: 0.446, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0139, loss_rpn_bbox: 0.0483, loss_cls: 0.1883, acc: 91.9629, loss_bbox: 0.1334, loss: 0.3840\n",
            "2022-04-20 05:07:18,669 - mmdet - INFO - Epoch [2][400/414]\tlr: 2.000e-02, eta: 0:06:16, time: 0.446, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0096, loss_rpn_bbox: 0.0529, loss_cls: 0.1849, acc: 92.0371, loss_bbox: 0.1230, loss: 0.3703\n",
            "2022-04-20 05:07:24,693 - mmdet - INFO - Saving checkpoint at 2 epochs\n",
            "2022-04-20 05:07:51,179 - mmdet - INFO - Epoch [3][50/414]\tlr: 2.000e-02, eta: 0:05:44, time: 0.493, data_time: 0.055, memory: 4076, loss_rpn_cls: 0.0130, loss_rpn_bbox: 0.0511, loss_cls: 0.1712, acc: 92.7227, loss_bbox: 0.1197, loss: 0.3550\n",
            "2022-04-20 05:08:13,608 - mmdet - INFO - Epoch [3][100/414]\tlr: 2.000e-02, eta: 0:05:22, time: 0.448, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0092, loss_rpn_bbox: 0.0470, loss_cls: 0.1818, acc: 92.3516, loss_bbox: 0.1197, loss: 0.3577\n",
            "2022-04-20 05:08:36,172 - mmdet - INFO - Epoch [3][150/414]\tlr: 2.000e-02, eta: 0:05:00, time: 0.452, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0100, loss_rpn_bbox: 0.0480, loss_cls: 0.1692, acc: 92.8691, loss_bbox: 0.1111, loss: 0.3383\n",
            "2022-04-20 05:08:58,612 - mmdet - INFO - Epoch [3][200/414]\tlr: 2.000e-02, eta: 0:04:38, time: 0.449, data_time: 0.009, memory: 4076, loss_rpn_cls: 0.0092, loss_rpn_bbox: 0.0416, loss_cls: 0.1636, acc: 93.0352, loss_bbox: 0.1088, loss: 0.3231\n",
            "2022-04-20 05:09:21,221 - mmdet - INFO - Epoch [3][250/414]\tlr: 2.000e-02, eta: 0:04:16, time: 0.452, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0092, loss_rpn_bbox: 0.0464, loss_cls: 0.1630, acc: 93.0508, loss_bbox: 0.1082, loss: 0.3268\n",
            "2022-04-20 05:09:43,526 - mmdet - INFO - Epoch [3][300/414]\tlr: 2.000e-02, eta: 0:03:54, time: 0.446, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0086, loss_rpn_bbox: 0.0413, loss_cls: 0.1602, acc: 93.1465, loss_bbox: 0.1061, loss: 0.3162\n",
            "2022-04-20 05:10:05,856 - mmdet - INFO - Epoch [3][350/414]\tlr: 2.000e-02, eta: 0:03:32, time: 0.447, data_time: 0.010, memory: 4076, loss_rpn_cls: 0.0098, loss_rpn_bbox: 0.0396, loss_cls: 0.1594, acc: 93.2461, loss_bbox: 0.1122, loss: 0.3210\n",
            "2022-04-20 05:10:28,156 - mmdet - INFO - Epoch [3][400/414]\tlr: 2.000e-02, eta: 0:03:10, time: 0.446, data_time: 0.009, memory: 4076, loss_rpn_cls: 0.0071, loss_rpn_bbox: 0.0440, loss_cls: 0.1539, acc: 93.3965, loss_bbox: 0.1079, loss: 0.3130\n",
            "2022-04-20 05:10:34,139 - mmdet - INFO - Saving checkpoint at 3 epochs\n",
            "2022-04-20 05:11:00,630 - mmdet - INFO - Epoch [4][50/414]\tlr: 2.000e-03, eta: 0:02:40, time: 0.491, data_time: 0.056, memory: 4076, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0311, loss_cls: 0.1461, acc: 93.8008, loss_bbox: 0.0945, loss: 0.2786\n",
            "2022-04-20 05:11:23,069 - mmdet - INFO - Epoch [4][100/414]\tlr: 2.000e-03, eta: 0:02:18, time: 0.449, data_time: 0.009, memory: 4077, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0305, loss_cls: 0.1382, acc: 94.1562, loss_bbox: 0.0933, loss: 0.2671\n",
            "2022-04-20 05:11:45,602 - mmdet - INFO - Epoch [4][150/414]\tlr: 2.000e-03, eta: 0:01:56, time: 0.451, data_time: 0.010, memory: 4077, loss_rpn_cls: 0.0041, loss_rpn_bbox: 0.0296, loss_cls: 0.1318, acc: 94.4727, loss_bbox: 0.0914, loss: 0.2569\n",
            "2022-04-20 05:12:08,081 - mmdet - INFO - Epoch [4][200/414]\tlr: 2.000e-03, eta: 0:01:34, time: 0.449, data_time: 0.010, memory: 4077, loss_rpn_cls: 0.0048, loss_rpn_bbox: 0.0269, loss_cls: 0.1206, acc: 94.9609, loss_bbox: 0.0827, loss: 0.2350\n",
            "2022-04-20 05:12:30,694 - mmdet - INFO - Epoch [4][250/414]\tlr: 2.000e-03, eta: 0:01:12, time: 0.452, data_time: 0.010, memory: 4077, loss_rpn_cls: 0.0036, loss_rpn_bbox: 0.0263, loss_cls: 0.1191, acc: 94.9473, loss_bbox: 0.0811, loss: 0.2301\n",
            "2022-04-20 05:12:53,057 - mmdet - INFO - Epoch [4][300/414]\tlr: 2.000e-03, eta: 0:00:50, time: 0.447, data_time: 0.010, memory: 4077, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0273, loss_cls: 0.1191, acc: 94.9453, loss_bbox: 0.0842, loss: 0.2349\n",
            "2022-04-20 05:13:15,463 - mmdet - INFO - Epoch [4][350/414]\tlr: 2.000e-03, eta: 0:00:28, time: 0.448, data_time: 0.011, memory: 4077, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0257, loss_cls: 0.1154, acc: 95.1660, loss_bbox: 0.0806, loss: 0.2262\n",
            "2022-04-20 05:13:37,778 - mmdet - INFO - Epoch [4][400/414]\tlr: 2.000e-03, eta: 0:00:06, time: 0.447, data_time: 0.010, memory: 4077, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0268, loss_cls: 0.1229, acc: 94.8574, loss_bbox: 0.0858, loss: 0.2400\n",
            "2022-04-20 05:13:43,772 - mmdet - INFO - Saving checkpoint at 4 epochs\n"
          ]
        }
      ],
      "source": [
        "import os.path as osp\n",
        "\n",
        "from mmtrack.datasets import build_dataset\n",
        "from mmdet.apis import train_detector as train_model\n",
        "from mmdet.models import build_detector as build_model\n",
        "\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "model = build_model(cfg.model.detector)\n",
        "model.init_weights()\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "train_model(model, datasets, cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f747c1f-7944-49f2-b9fc-a51dc3f85857",
      "metadata": {
        "id": "7f747c1f-7944-49f2-b9fc-a51dc3f85857",
        "tags": []
      },
      "source": [
        "### **Train a ReID model for MOT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6705deeb-a9d7-42e2-9d52-b51b7b588d1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6705deeb-a9d7-42e2-9d52-b51b7b588d1f",
        "outputId": "b3b974a6-9bfa-4c04-c568-aab06c6828d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config:\n",
            "dataset_type = 'ReIDDataset'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
            "    dict(\n",
            "        type='SeqResize',\n",
            "        img_scale=(128, 256),\n",
            "        share_params=False,\n",
            "        keep_ratio=False,\n",
            "        bbox_clip_border=False,\n",
            "        override=False),\n",
            "    dict(\n",
            "        type='SeqRandomFlip',\n",
            "        share_params=False,\n",
            "        flip_ratio=0.5,\n",
            "        direction='horizontal'),\n",
            "    dict(\n",
            "        type='SeqNormalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='VideoCollect', keys=['img', 'gt_label']),\n",
            "    dict(type='ReIDFormatBundle')\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='Resize', img_scale=(128, 256), keep_ratio=False),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='ImageToTensor', keys=['img']),\n",
            "    dict(type='Collect', keys=['img'], meta_keys=[])\n",
            "]\n",
            "data_root = 'data/MOT17_tiny/'\n",
            "data = dict(\n",
            "    samples_per_gpu=1,\n",
            "    workers_per_gpu=2,\n",
            "    train=dict(\n",
            "        type='ReIDDataset',\n",
            "        triplet_sampler=dict(num_ids=8, ins_per_id=4),\n",
            "        data_prefix='data/MOT17_tiny/reid/imgs',\n",
            "        ann_file='data/MOT17_tiny/reid/meta/train_9.txt',\n",
            "        pipeline=[\n",
            "            dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
            "            dict(\n",
            "                type='SeqResize',\n",
            "                img_scale=(128, 256),\n",
            "                share_params=False,\n",
            "                keep_ratio=False,\n",
            "                bbox_clip_border=False,\n",
            "                override=False),\n",
            "            dict(\n",
            "                type='SeqRandomFlip',\n",
            "                share_params=False,\n",
            "                flip_ratio=0.5,\n",
            "                direction='horizontal'),\n",
            "            dict(\n",
            "                type='SeqNormalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='VideoCollect', keys=['img', 'gt_label']),\n",
            "            dict(type='ReIDFormatBundle')\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='ReIDDataset',\n",
            "        triplet_sampler=None,\n",
            "        data_prefix='data/MOT17_tiny/reid/imgs',\n",
            "        ann_file='data/MOT17_tiny/reid/meta/val_20.txt',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='Resize', img_scale=(128, 256), keep_ratio=False),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'], meta_keys=[])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='ReIDDataset',\n",
            "        triplet_sampler=None,\n",
            "        data_prefix='data/MOT17_tiny/reid/imgs',\n",
            "        ann_file='data/MOT17_tiny/reid/meta/val_20.txt',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='Resize', img_scale=(128, 256), keep_ratio=False),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'], meta_keys=[])\n",
            "        ]))\n",
            "evaluation = dict(interval=1, metric='mAP')\n",
            "optimizer = dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=None)\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "opencv_num_threads = 0\n",
            "mp_start_method = 'fork'\n",
            "TRAIN_REID = True\n",
            "model = dict(\n",
            "    reid=dict(\n",
            "        type='BaseReID',\n",
            "        backbone=dict(\n",
            "            type='ResNet',\n",
            "            depth=50,\n",
            "            num_stages=4,\n",
            "            out_indices=(3, ),\n",
            "            style='pytorch'),\n",
            "        neck=dict(type='GlobalAveragePooling', kernel_size=(8, 4), stride=1),\n",
            "        head=dict(\n",
            "            type='LinearReIDHead',\n",
            "            num_fcs=1,\n",
            "            in_channels=2048,\n",
            "            fc_channels=1024,\n",
            "            out_channels=128,\n",
            "            num_classes=380,\n",
            "            loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
            "            loss_pairwise=dict(\n",
            "                type='TripletLoss', margin=0.3, loss_weight=1.0),\n",
            "            norm_cfg=dict(type='BN1d'),\n",
            "            act_cfg=dict(type='ReLU')),\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained',\n",
            "            checkpoint=\n",
            "            'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth'\n",
            "        )))\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=200,\n",
            "    warmup_ratio=0.005,\n",
            "    step=[1])\n",
            "total_epochs = 2\n",
            "work_dir = './tutorial_exps/reid'\n",
            "seed = 0\n",
            "gpu_ids = range(0, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import mmcv\n",
        "from mmdet.apis import set_random_seed\n",
        "cfg = mmcv.Config.fromfile('./configs/reid/resnet50_b32x8_MOT17.py')\n",
        "cfg.data_root = 'data/MOT17_tiny/'\n",
        "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.train.ann_file = 'data/MOT17_tiny/reid/meta/train_9.txt'\n",
        "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "\n",
        "cfg.data.test.data_prefix = cfg.data.test.data_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.train.data_prefix = cfg.data.train.data_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.val.data_prefix = cfg.data.val.data_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "\n",
        "# learning policy\n",
        "cfg.lr_config = dict(\n",
        "    policy='step',\n",
        "    warmup='linear',\n",
        "    warmup_iters=200,\n",
        "    warmup_ratio=1.0 / 200,\n",
        "    step=[1])\n",
        "cfg.total_epochs = 2\n",
        "\n",
        "cfg.work_dir = './tutorial_exps/reid'\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12f2b54e-7e5f-4d95-9e27-528115717e03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1fc5eb2eaa6a4ed88a005a081bc24a70",
            "1f5d5858bede4242b51d1cb635c3f610",
            "9344070d5d004c0fb5c0bdf22632e343",
            "c4f0834d72224880b5a12217d95cb086",
            "92345bd0ebed40f4bf0a9ac4aad2bc5b",
            "4c38742132624fa38216e67e3771894f",
            "6b83dd17433745a3ae3d2ef9b4b932ad",
            "738b0850c1a4489a9147a63f3a587dd6",
            "9604ece7c2bb4e8ba8914d4430a72876",
            "7d5fd07e913046a6b5445a791197a287",
            "5a4441a529664fdfb5dc4d8de70b3421"
          ]
        },
        "id": "12f2b54e-7e5f-4d95-9e27-528115717e03",
        "outputId": "b3a6f9b1-5095-4b6f-82de-4c9f81e15e80"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-04-20 05:13:47,675 - mmtrack - INFO - initialize BaseReID with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth'}\n",
            "2022-04-20 05:13:47,678 - mmcv - INFO - load model from: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n",
            "2022-04-20 05:13:47,680 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n",
            "Downloading: \"https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\" to /root/.cache/torch/hub/checkpoints/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fc5eb2eaa6a4ed88a005a081bc24a70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/97.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-04-20 05:13:57,491 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: head.fc.weight, head.fc.bias\n",
            "\n",
            "missing keys in source state_dict: head.fcs.0.fc.weight, head.fcs.0.fc.bias, head.fcs.0.bn.weight, head.fcs.0.bn.bias, head.fcs.0.bn.running_mean, head.fcs.0.bn.running_var, head.fc_out.weight, head.fc_out.bias, head.bn.weight, head.bn.bias, head.bn.running_mean, head.bn.running_var, head.classifier.weight, head.classifier.bias\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/mmdet/apis/train.py:135: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.\n",
            "  'please set `runner` in your config.', UserWarning)\n",
            "2022-04-20 05:13:57,552 - mmdet - INFO - Start running, host: root@597380361c27, work_dir: /content/mmtracking/tutorial_exps/reid\n",
            "2022-04-20 05:13:57,553 - mmdet - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(ABOVE_NORMAL) OptimizerHook                      \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_run:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "2022-04-20 05:13:57,557 - mmdet - INFO - workflow: [('train', 1)], max: 2 epochs\n",
            "2022-04-20 05:13:57,559 - mmdet - INFO - Checkpoints will be saved to /content/mmtracking/tutorial_exps/reid by HardDiskBackend.\n",
            "2022-04-20 05:14:14,675 - mmdet - INFO - Epoch [1][50/1576]\tlr: 2.488e-02, eta: 0:17:31, time: 0.339, data_time: 0.052, memory: 4077, triplet_loss: 0.1025, ce_loss: 0.8317, top-1: 91.1875, loss: 0.9342\n",
            "2022-04-20 05:14:29,582 - mmdet - INFO - Epoch [1][100/1576]\tlr: 4.975e-02, eta: 0:16:12, time: 0.298, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0003, top-1: 100.0000, loss: 0.0003\n",
            "2022-04-20 05:14:44,624 - mmdet - INFO - Epoch [1][150/1576]\tlr: 7.463e-02, eta: 0:15:38, time: 0.301, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:14:59,453 - mmdet - INFO - Epoch [1][200/1576]\tlr: 9.950e-02, eta: 0:15:11, time: 0.297, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:15:14,151 - mmdet - INFO - Epoch [1][250/1576]\tlr: 1.000e-01, eta: 0:14:47, time: 0.294, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:15:28,850 - mmdet - INFO - Epoch [1][300/1576]\tlr: 1.000e-01, eta: 0:14:26, time: 0.294, data_time: 0.007, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:15:43,596 - mmdet - INFO - Epoch [1][350/1576]\tlr: 1.000e-01, eta: 0:14:07, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:15:58,405 - mmdet - INFO - Epoch [1][400/1576]\tlr: 1.000e-01, eta: 0:13:50, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:16:13,239 - mmdet - INFO - Epoch [1][450/1576]\tlr: 1.000e-01, eta: 0:13:33, time: 0.297, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:16:27,987 - mmdet - INFO - Epoch [1][500/1576]\tlr: 1.000e-01, eta: 0:13:16, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:16:42,705 - mmdet - INFO - Epoch [1][550/1576]\tlr: 1.000e-01, eta: 0:13:00, time: 0.294, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:16:57,480 - mmdet - INFO - Epoch [1][600/1576]\tlr: 1.000e-01, eta: 0:12:44, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:17:12,310 - mmdet - INFO - Epoch [1][650/1576]\tlr: 1.000e-01, eta: 0:12:28, time: 0.297, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:17:27,116 - mmdet - INFO - Epoch [1][700/1576]\tlr: 1.000e-01, eta: 0:12:13, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:17:41,884 - mmdet - INFO - Epoch [1][750/1576]\tlr: 1.000e-01, eta: 0:11:57, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:17:56,633 - mmdet - INFO - Epoch [1][800/1576]\tlr: 1.000e-01, eta: 0:11:42, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:18:11,409 - mmdet - INFO - Epoch [1][850/1576]\tlr: 1.000e-01, eta: 0:11:27, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:18:26,189 - mmdet - INFO - Epoch [1][900/1576]\tlr: 1.000e-01, eta: 0:11:11, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:18:40,972 - mmdet - INFO - Epoch [1][950/1576]\tlr: 1.000e-01, eta: 0:10:56, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:18:55,750 - mmdet - INFO - Epoch [1][1000/1576]\tlr: 1.000e-01, eta: 0:10:41, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:19:10,534 - mmdet - INFO - Epoch [1][1050/1576]\tlr: 1.000e-01, eta: 0:10:26, time: 0.296, data_time: 0.009, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:19:25,299 - mmdet - INFO - Epoch [1][1100/1576]\tlr: 1.000e-01, eta: 0:10:11, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0001, top-1: 100.0000, loss: 0.0001\n",
            "2022-04-20 05:19:40,061 - mmdet - INFO - Epoch [1][1150/1576]\tlr: 1.000e-01, eta: 0:09:55, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:19:54,816 - mmdet - INFO - Epoch [1][1200/1576]\tlr: 1.000e-01, eta: 0:09:40, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:20:09,564 - mmdet - INFO - Epoch [1][1250/1576]\tlr: 1.000e-01, eta: 0:09:25, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:20:24,351 - mmdet - INFO - Epoch [1][1300/1576]\tlr: 1.000e-01, eta: 0:09:10, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:20:39,116 - mmdet - INFO - Epoch [1][1350/1576]\tlr: 1.000e-01, eta: 0:08:55, time: 0.295, data_time: 0.007, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:20:53,899 - mmdet - INFO - Epoch [1][1400/1576]\tlr: 1.000e-01, eta: 0:08:40, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:21:08,662 - mmdet - INFO - Epoch [1][1450/1576]\tlr: 1.000e-01, eta: 0:08:25, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:21:23,452 - mmdet - INFO - Epoch [1][1500/1576]\tlr: 1.000e-01, eta: 0:08:10, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:21:38,229 - mmdet - INFO - Epoch [1][1550/1576]\tlr: 1.000e-01, eta: 0:07:55, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:21:45,866 - mmdet - INFO - Saving checkpoint at 1 epochs\n",
            "2022-04-20 05:22:04,077 - mmdet - INFO - Epoch [2][50/1576]\tlr: 1.000e-02, eta: 0:07:28, time: 0.341, data_time: 0.051, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:22:18,897 - mmdet - INFO - Epoch [2][100/1576]\tlr: 1.000e-02, eta: 0:07:13, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:22:33,683 - mmdet - INFO - Epoch [2][150/1576]\tlr: 1.000e-02, eta: 0:06:59, time: 0.296, data_time: 0.007, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:22:48,454 - mmdet - INFO - Epoch [2][200/1576]\tlr: 1.000e-02, eta: 0:06:44, time: 0.295, data_time: 0.007, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:23:03,198 - mmdet - INFO - Epoch [2][250/1576]\tlr: 1.000e-02, eta: 0:06:29, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:23:17,976 - mmdet - INFO - Epoch [2][300/1576]\tlr: 1.000e-02, eta: 0:06:15, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:23:32,734 - mmdet - INFO - Epoch [2][350/1576]\tlr: 1.000e-02, eta: 0:06:00, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:23:47,520 - mmdet - INFO - Epoch [2][400/1576]\tlr: 1.000e-02, eta: 0:05:45, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:24:02,320 - mmdet - INFO - Epoch [2][450/1576]\tlr: 1.000e-02, eta: 0:05:31, time: 0.296, data_time: 0.009, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:24:17,108 - mmdet - INFO - Epoch [2][500/1576]\tlr: 1.000e-02, eta: 0:05:16, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:24:31,876 - mmdet - INFO - Epoch [2][550/1576]\tlr: 1.000e-02, eta: 0:05:01, time: 0.295, data_time: 0.007, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:24:46,655 - mmdet - INFO - Epoch [2][600/1576]\tlr: 1.000e-02, eta: 0:04:47, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:25:01,427 - mmdet - INFO - Epoch [2][650/1576]\tlr: 1.000e-02, eta: 0:04:32, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:25:16,196 - mmdet - INFO - Epoch [2][700/1576]\tlr: 1.000e-02, eta: 0:04:17, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:25:30,965 - mmdet - INFO - Epoch [2][750/1576]\tlr: 1.000e-02, eta: 0:04:03, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:25:45,738 - mmdet - INFO - Epoch [2][800/1576]\tlr: 1.000e-02, eta: 0:03:48, time: 0.295, data_time: 0.007, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:26:00,530 - mmdet - INFO - Epoch [2][850/1576]\tlr: 1.000e-02, eta: 0:03:33, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:26:15,302 - mmdet - INFO - Epoch [2][900/1576]\tlr: 1.000e-02, eta: 0:03:18, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:26:30,094 - mmdet - INFO - Epoch [2][950/1576]\tlr: 1.000e-02, eta: 0:03:04, time: 0.296, data_time: 0.009, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:26:44,876 - mmdet - INFO - Epoch [2][1000/1576]\tlr: 1.000e-02, eta: 0:02:49, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:26:59,644 - mmdet - INFO - Epoch [2][1050/1576]\tlr: 1.000e-02, eta: 0:02:34, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:27:14,441 - mmdet - INFO - Epoch [2][1100/1576]\tlr: 1.000e-02, eta: 0:02:20, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:27:29,222 - mmdet - INFO - Epoch [2][1150/1576]\tlr: 1.000e-02, eta: 0:02:05, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:27:43,996 - mmdet - INFO - Epoch [2][1200/1576]\tlr: 1.000e-02, eta: 0:01:50, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:27:58,760 - mmdet - INFO - Epoch [2][1250/1576]\tlr: 1.000e-02, eta: 0:01:36, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:28:13,523 - mmdet - INFO - Epoch [2][1300/1576]\tlr: 1.000e-02, eta: 0:01:21, time: 0.295, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:28:28,302 - mmdet - INFO - Epoch [2][1350/1576]\tlr: 1.000e-02, eta: 0:01:06, time: 0.296, data_time: 0.009, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:28:43,082 - mmdet - INFO - Epoch [2][1400/1576]\tlr: 1.000e-02, eta: 0:00:51, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:28:57,869 - mmdet - INFO - Epoch [2][1450/1576]\tlr: 1.000e-02, eta: 0:00:37, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:29:12,650 - mmdet - INFO - Epoch [2][1500/1576]\tlr: 1.000e-02, eta: 0:00:22, time: 0.296, data_time: 0.009, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:29:27,444 - mmdet - INFO - Epoch [2][1550/1576]\tlr: 1.000e-02, eta: 0:00:07, time: 0.296, data_time: 0.008, memory: 4077, triplet_loss: 0.0000, ce_loss: 0.0002, top-1: 100.0000, loss: 0.0002\n",
            "2022-04-20 05:29:35,087 - mmdet - INFO - Saving checkpoint at 2 epochs\n"
          ]
        }
      ],
      "source": [
        "from mmtrack.datasets import build_dataset\n",
        "from mmdet.apis import train_detector as train_model\n",
        "from mmtrack.models import build_reid as build_model\n",
        "\n",
        "\n",
        "model = build_model(cfg.model.reid)\n",
        "model.init_weights()\n",
        "datasets = [build_dataset(cfg.data.train)]\n",
        "model.CLASSES = datasets[0].CLASSES\n",
        "\n",
        "train_model(model, datasets, cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5ac4b40-7023-498a-9ddf-bc06ff2100af",
      "metadata": {
        "id": "e5ac4b40-7023-498a-9ddf-bc06ff2100af",
        "tags": []
      },
      "source": [
        "### **Test the DeepSORT model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c837c657-cc81-426d-8060-ad19f5494461",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c837c657-cc81-426d-8060-ad19f5494461",
        "outputId": "d33fa793-8dc1-4186-dac0-49d97355c69a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config:\n",
            "model = dict(\n",
            "    detector=dict(\n",
            "        type='FasterRCNN',\n",
            "        backbone=dict(\n",
            "            type='ResNet',\n",
            "            depth=50,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=True),\n",
            "            norm_eval=True,\n",
            "            style='pytorch',\n",
            "            init_cfg=dict(\n",
            "                type='Pretrained', checkpoint='torchvision://resnet50')),\n",
            "        neck=dict(\n",
            "            type='FPN',\n",
            "            in_channels=[256, 512, 1024, 2048],\n",
            "            out_channels=256,\n",
            "            num_outs=5),\n",
            "        rpn_head=dict(\n",
            "            type='RPNHead',\n",
            "            in_channels=256,\n",
            "            feat_channels=256,\n",
            "            anchor_generator=dict(\n",
            "                type='AnchorGenerator',\n",
            "                scales=[8],\n",
            "                ratios=[0.5, 1.0, 2.0],\n",
            "                strides=[4, 8, 16, 32, 64]),\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[1.0, 1.0, 1.0, 1.0],\n",
            "                clip_border=False),\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "            loss_bbox=dict(\n",
            "                type='SmoothL1Loss', beta=0.1111111111111111,\n",
            "                loss_weight=1.0)),\n",
            "        roi_head=dict(\n",
            "            type='StandardRoIHead',\n",
            "            bbox_roi_extractor=dict(\n",
            "                type='SingleRoIExtractor',\n",
            "                roi_layer=dict(\n",
            "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "                out_channels=256,\n",
            "                featmap_strides=[4, 8, 16, 32]),\n",
            "            bbox_head=dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=1,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.1, 0.1, 0.2, 0.2],\n",
            "                    clip_border=False),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', loss_weight=1.0))),\n",
            "        train_cfg=dict(\n",
            "            rpn=dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.7,\n",
            "                    neg_iou_thr=0.3,\n",
            "                    min_pos_iou=0.3,\n",
            "                    match_low_quality=True,\n",
            "                    ignore_iof_thr=-1),\n",
            "                sampler=dict(\n",
            "                    type='RandomSampler',\n",
            "                    num=256,\n",
            "                    pos_fraction=0.5,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=False),\n",
            "                allowed_border=-1,\n",
            "                pos_weight=-1,\n",
            "                debug=False),\n",
            "            rpn_proposal=dict(\n",
            "                nms_pre=2000,\n",
            "                max_per_img=1000,\n",
            "                nms=dict(type='nms', iou_threshold=0.7),\n",
            "                min_bbox_size=0),\n",
            "            rcnn=dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.5,\n",
            "                    neg_iou_thr=0.5,\n",
            "                    min_pos_iou=0.5,\n",
            "                    match_low_quality=False,\n",
            "                    ignore_iof_thr=-1),\n",
            "                sampler=dict(\n",
            "                    type='RandomSampler',\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=True),\n",
            "                pos_weight=-1,\n",
            "                debug=False)),\n",
            "        test_cfg=dict(\n",
            "            rpn=dict(\n",
            "                nms_pre=1000,\n",
            "                max_per_img=1000,\n",
            "                nms=dict(type='nms', iou_threshold=0.7),\n",
            "                min_bbox_size=0),\n",
            "            rcnn=dict(\n",
            "                score_thr=0.05,\n",
            "                nms=dict(type='nms', iou_threshold=0.5),\n",
            "                max_per_img=100)),\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained',\n",
            "            checkpoint='./tutorial_exps/detector/epoch_4.pth')),\n",
            "    type='DeepSORT',\n",
            "    motion=dict(type='KalmanFilter', center_only=False),\n",
            "    reid=dict(\n",
            "        type='BaseReID',\n",
            "        backbone=dict(\n",
            "            type='ResNet',\n",
            "            depth=50,\n",
            "            num_stages=4,\n",
            "            out_indices=(3, ),\n",
            "            style='pytorch'),\n",
            "        neck=dict(type='GlobalAveragePooling', kernel_size=(8, 4), stride=1),\n",
            "        head=dict(\n",
            "            type='LinearReIDHead',\n",
            "            num_fcs=1,\n",
            "            in_channels=2048,\n",
            "            fc_channels=1024,\n",
            "            out_channels=128,\n",
            "            num_classes=380,\n",
            "            loss=dict(type='CrossEntropyLoss', loss_weight=1.0),\n",
            "            loss_pairwise=dict(\n",
            "                type='TripletLoss', margin=0.3, loss_weight=1.0),\n",
            "            norm_cfg=dict(type='BN1d'),\n",
            "            act_cfg=dict(type='ReLU')),\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained', checkpoint='./tutorial_exps/reid/epoch_2.pth')),\n",
            "    tracker=dict(\n",
            "        type='SortTracker',\n",
            "        obj_score_thr=0.5,\n",
            "        reid=dict(\n",
            "            num_samples=10,\n",
            "            img_scale=(256, 128),\n",
            "            img_norm_cfg=None,\n",
            "            match_score_thr=2.0),\n",
            "        match_iou_thr=0.5,\n",
            "        momentums=None,\n",
            "        num_tentatives=2,\n",
            "        num_frames_retain=100))\n",
            "dataset_type = 'MOTChallengeDataset'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
            "    dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
            "    dict(\n",
            "        type='SeqResize',\n",
            "        img_scale=(1088, 1088),\n",
            "        share_params=True,\n",
            "        ratio_range=(0.8, 1.2),\n",
            "        keep_ratio=True,\n",
            "        bbox_clip_border=False),\n",
            "    dict(type='SeqPhotoMetricDistortion', share_params=True),\n",
            "    dict(\n",
            "        type='SeqRandomCrop',\n",
            "        share_params=False,\n",
            "        crop_size=(1088, 1088),\n",
            "        bbox_clip_border=False),\n",
            "    dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
            "    dict(\n",
            "        type='SeqNormalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='SeqPad', size_divisor=32),\n",
            "    dict(type='MatchInstances', skip_nomatch=True),\n",
            "    dict(\n",
            "        type='VideoCollect',\n",
            "        keys=[\n",
            "            'img', 'gt_bboxes', 'gt_labels', 'gt_match_indices',\n",
            "            'gt_instance_ids'\n",
            "        ]),\n",
            "    dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(1088, 1088),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=True),\n",
            "            dict(type='RandomFlip'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='VideoCollect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data_root = 'data/MOT17_tiny/'\n",
            "data = dict(\n",
            "    samples_per_gpu=2,\n",
            "    workers_per_gpu=2,\n",
            "    train=dict(\n",
            "        type='MOTChallengeDataset',\n",
            "        visibility_thr=-1,\n",
            "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
            "        img_prefix='data/MOT17_tiny/train',\n",
            "        ref_img_sampler=dict(\n",
            "            num_ref_imgs=1,\n",
            "            frame_range=10,\n",
            "            filter_key_img=True,\n",
            "            method='uniform'),\n",
            "        pipeline=[\n",
            "            dict(type='LoadMultiImagesFromFile', to_float32=True),\n",
            "            dict(type='SeqLoadAnnotations', with_bbox=True, with_track=True),\n",
            "            dict(\n",
            "                type='SeqResize',\n",
            "                img_scale=(1088, 1088),\n",
            "                share_params=True,\n",
            "                ratio_range=(0.8, 1.2),\n",
            "                keep_ratio=True,\n",
            "                bbox_clip_border=False),\n",
            "            dict(type='SeqPhotoMetricDistortion', share_params=True),\n",
            "            dict(\n",
            "                type='SeqRandomCrop',\n",
            "                share_params=False,\n",
            "                crop_size=(1088, 1088),\n",
            "                bbox_clip_border=False),\n",
            "            dict(type='SeqRandomFlip', share_params=True, flip_ratio=0.5),\n",
            "            dict(\n",
            "                type='SeqNormalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='SeqPad', size_divisor=32),\n",
            "            dict(type='MatchInstances', skip_nomatch=True),\n",
            "            dict(\n",
            "                type='VideoCollect',\n",
            "                keys=[\n",
            "                    'img', 'gt_bboxes', 'gt_labels', 'gt_match_indices',\n",
            "                    'gt_instance_ids'\n",
            "                ]),\n",
            "            dict(type='SeqDefaultFormatBundle', ref_prefix='ref')\n",
            "        ]),\n",
            "    val=dict(\n",
            "        type='MOTChallengeDataset',\n",
            "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
            "        img_prefix='data/MOT17_tiny/train',\n",
            "        ref_img_sampler=None,\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1088, 1088),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='VideoCollect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='MOTChallengeDataset',\n",
            "        ann_file='data/MOT17_tiny/annotations/half-val_cocoformat.json',\n",
            "        img_prefix='data/MOT17_tiny/train',\n",
            "        ref_img_sampler=None,\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(1088, 1088),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='Pad', size_divisor=32),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='VideoCollect', keys=['img'])\n",
            "                ])\n",
            "        ],\n",
            "        test_mode=True))\n",
            "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=None)\n",
            "checkpoint_config = dict(interval=1)\n",
            "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "opencv_num_threads = 0\n",
            "mp_start_method = 'fork'\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=100,\n",
            "    warmup_ratio=0.01,\n",
            "    step=[3])\n",
            "total_epochs = 4\n",
            "evaluation = dict(metric=['bbox', 'track'], interval=1)\n",
            "search_metrics = ['MOTA', 'IDF1', 'FN', 'FP', 'IDs', 'MT', 'ML']\n",
            "work_dir = './tutorial_exps'\n",
            "seed = 0\n",
            "gpu_ids = range(0, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import mmcv\n",
        "from mmdet.apis import set_random_seed\n",
        "cfg = mmcv.Config.fromfile('./configs/mot/deepsort/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py')\n",
        "cfg.data_root = 'data/MOT17_tiny/'\n",
        "cfg.data.test.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.train.ann_file = cfg.data.test.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.val.ann_file = cfg.data.val.ann_file.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "\n",
        "cfg.data.test.img_prefix = cfg.data.test.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.train.img_prefix = cfg.data.train.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "cfg.data.val.img_prefix = cfg.data.val.img_prefix.replace('data/MOT17/','data/MOT17_tiny/')\n",
        "\n",
        "cfg.model.detector.init_cfg.checkpoint = './tutorial_exps/detector/epoch_4.pth'\n",
        "cfg.model.reid.init_cfg.checkpoint = './tutorial_exps/reid/epoch_2.pth'\n",
        "\n",
        "cfg.work_dir = './tutorial_exps'\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "cfg.data.test.test_mode = True\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29c9f531-3ea9-42d3-9fb3-bcdd13594406",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "29c9f531-3ea9-42d3-9fb3-bcdd13594406",
        "outputId": "7c5837e7-78bb-41c7-f0c7-e4dadada5a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.12s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-04-20 05:29:38,354 - mmtrack - INFO - initialize FasterRCNN with init_cfg {'type': 'Pretrained', 'checkpoint': './tutorial_exps/detector/epoch_4.pth'}\n",
            "2022-04-20 05:29:38,356 - mmcv - INFO - load model from: ./tutorial_exps/detector/epoch_4.pth\n",
            "2022-04-20 05:29:38,359 - mmcv - INFO - load checkpoint from local path: ./tutorial_exps/detector/epoch_4.pth\n",
            "2022-04-20 05:29:38,667 - mmtrack - INFO - initialize BaseReID with init_cfg {'type': 'Pretrained', 'checkpoint': './tutorial_exps/reid/epoch_2.pth'}\n",
            "2022-04-20 05:29:38,669 - mmcv - INFO - load model from: ./tutorial_exps/reid/epoch_2.pth\n",
            "2022-04-20 05:29:38,672 - mmcv - INFO - load checkpoint from local path: ./tutorial_exps/reid/epoch_2.pth\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: The model doesn't have classes\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 823/823, 5.1 task/s, elapsed: 162s, ETA:     0sEvaluate CLEAR MOT results.\n",
            "\n",
            "Eval Config:\n",
            "USE_PARALLEL         : False                         \n",
            "NUM_PARALLEL_CORES   : 8                             \n",
            "BREAK_ON_ERROR       : True                          \n",
            "RETURN_ON_ERROR      : False                         \n",
            "LOG_ON_ERROR         : /usr/local/lib/python3.7/dist-packages/error_log.txt\n",
            "PRINT_RESULTS        : True                          \n",
            "PRINT_ONLY_COMBINED  : False                         \n",
            "PRINT_CONFIG         : True                          \n",
            "TIME_PROGRESS        : True                          \n",
            "DISPLAY_LESS_PROGRESS : True                          \n",
            "OUTPUT_SUMMARY       : True                          \n",
            "OUTPUT_EMPTY_CLASSES : True                          \n",
            "OUTPUT_DETAILED      : True                          \n",
            "PLOT_CURVES          : True                          \n",
            "\n",
            "MotChallenge2DBox Config:\n",
            "GT_FOLDER            : data/MOT17_tiny/train         \n",
            "TRACKERS_FOLDER      : /tmp/tmpbbh8obye              \n",
            "OUTPUT_FOLDER        : None                          \n",
            "TRACKERS_TO_EVAL     : ['track']                     \n",
            "CLASSES_TO_EVAL      : ['pedestrian']                \n",
            "BENCHMARK            : MOT17                         \n",
            "SPLIT_TO_EVAL        : train                         \n",
            "INPUT_AS_ZIP         : False                         \n",
            "PRINT_CONFIG         : True                          \n",
            "DO_PREPROC           : True                          \n",
            "TRACKER_SUB_FOLDER   :                               \n",
            "OUTPUT_SUB_FOLDER    :                               \n",
            "TRACKER_DISPLAY_NAMES : None                          \n",
            "SEQMAP_FOLDER        : None                          \n",
            "SEQMAP_FILE          : /tmp/tmpbbh8obye/videoseq.txt \n",
            "SEQ_INFO             : None                          \n",
            "GT_LOC_FORMAT        : {gt_folder}/{seq}/gt/gt_half-val.txt\n",
            "SKIP_SPLIT_FOL       : True                          \n",
            "\n",
            "Evaluating 1 tracker(s) on 2 sequence(s) for 1 class(es) on MotChallenge2DBox dataset using the following metrics: HOTA, Count\n",
            "\n",
            "\n",
            "Evaluating track\n",
            "\n",
            "1 eval_sequence(MOT17-02-FRCNN, track)                                   0.4733 sec\n",
            "2 eval_sequence(MOT17-04-FRCNN, track)                                   1.1452 sec\n",
            "\n",
            "All sequences for track finished in 1.62 seconds\n",
            "\n",
            "HOTA: track-pedestrian             HOTA      DetA      AssA      DetRe     DetPr     AssRe     AssPr     LocA      RHOTA     HOTA(0)   LocA(0)   HOTALocA(0)\n",
            "MOT17-02-FRCNN                     26.163    39.63     18.033    46.541    63.74     20.987    55.171    79.643    28.582    33.942    69.284    23.516    \n",
            "MOT17-04-FRCNN                     50.13     66.595    38.789    71.095    82.128    44.817    58.181    84.906    52.104    59.437    81.81     48.625    \n",
            "COMBINED                           44.066    58.107    34.579    63.972    77.414    40.031    57.716    83.727    46.545    53.072    78.788    41.815    \n",
            "\n",
            "Count: track-pedestrian            Dets      GT_Dets   IDs       GT_IDs    \n",
            "MOT17-02-FRCNN                     7214      9880      353       53        \n",
            "MOT17-04-FRCNN                     20930     24178     164       69        \n",
            "COMBINED                           28144     34058     517       122       \n",
            "                IDF1   IDP   IDR  Rcll  Prcn  GT MT PT ML   FP   FN  IDs   FM  MOTA  MOTP IDt IDa IDm      HOTA\n",
            "MOT17-02-FRCNN 29.6% 35.1% 25.6% 55.1% 75.5%  53 12 29 12 1766 4432 1021  343 26.9% 0.219 382 201   8  0.261632\n",
            "MOT17-04-FRCNN 52.8% 56.9% 49.2% 84.2% 97.2%  69 48 20  1  583 3831 1267  332 76.5% 0.172 414  74   7  0.501298\n",
            "OVERALL        46.4% 51.3% 42.4% 75.7% 91.7% 122 60 49 13 2349 8263 2288  675 62.1% 0.182 796 275  15  0.440663\n",
            "{'IDF1': 0.464, 'IDP': 0.513, 'IDR': 0.424, 'Rcll': 0.757, 'Prcn': 0.917, 'GT': 122, 'MT': 60, 'PT': 49, 'ML': 13, 'FP': 2349, 'FN': 8263, 'IDs': 2288, 'FM': 675, 'MOTA': 0.621, 'MOTP': 0.182, 'IDt': 796, 'IDa': 275, 'IDm': 15, 'HOTA': 0.441}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from mmtrack.datasets import build_dataloader\n",
        "from mmtrack.apis import init_model\n",
        "from mmcv.parallel import MMDataParallel\n",
        "from mmtrack.apis import single_gpu_test\n",
        "from mmtrack.datasets import build_dataset\n",
        "\n",
        "dataset = build_dataset(cfg.data.test)\n",
        "data_loader = build_dataloader(\n",
        "    dataset,\n",
        "    samples_per_gpu=1,\n",
        "    workers_per_gpu=cfg.data.workers_per_gpu,\n",
        "    dist=False,\n",
        "    shuffle=False)\n",
        "\n",
        "# build the model and load checkpoint\n",
        "model = init_model(cfg)\n",
        "\n",
        "model = MMDataParallel(model, device_ids=cfg.gpu_ids)\n",
        "outputs = single_gpu_test(model, data_loader)\n",
        "\n",
        "eval_kwargs = cfg.get('evaluation', {}).copy()\n",
        "# hard-code way to remove EvalHook args\n",
        "eval_hook_args = [\n",
        "    'interval', 'tmpdir', 'start', 'gpu_collect', 'save_best',\n",
        "    'rule', 'by_epoch'\n",
        "]\n",
        "for key in eval_hook_args:\n",
        "    eval_kwargs.pop(key, None)\n",
        "eval_kwargs.update(dict(metric=['track']))\n",
        "metric = dataset.evaluate(outputs, **eval_kwargs)\n",
        "print(metric)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1f5d5858bede4242b51d1cb635c3f610": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c38742132624fa38216e67e3771894f",
            "placeholder": "​",
            "style": "IPY_MODEL_6b83dd17433745a3ae3d2ef9b4b932ad",
            "value": "100%"
          }
        },
        "1fc5eb2eaa6a4ed88a005a081bc24a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f5d5858bede4242b51d1cb635c3f610",
              "IPY_MODEL_9344070d5d004c0fb5c0bdf22632e343",
              "IPY_MODEL_c4f0834d72224880b5a12217d95cb086"
            ],
            "layout": "IPY_MODEL_92345bd0ebed40f4bf0a9ac4aad2bc5b"
          }
        },
        "3ed731e3194e4465aa7b79579f8eaaca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_750088e53a064a13872ed5fa5616face",
            "placeholder": "​",
            "style": "IPY_MODEL_eb8e5c96ffea40e298a38db2b5a38ace",
            "value": " 160M/160M [00:12&lt;00:00, 13.2MB/s]"
          }
        },
        "4c38742132624fa38216e67e3771894f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a4441a529664fdfb5dc4d8de70b3421": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b83dd17433745a3ae3d2ef9b4b932ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "738b0850c1a4489a9147a63f3a587dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "750088e53a064a13872ed5fa5616face": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a4444bb015249ae9caa2b14c21fa0fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d5fd07e913046a6b5445a791197a287": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f20458c3bf7422fba34beba519c27bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e5d67b0f3fb4baaa7254a102464057b",
              "IPY_MODEL_f750ac53345746ee8c0364b5f850a56d",
              "IPY_MODEL_3ed731e3194e4465aa7b79579f8eaaca"
            ],
            "layout": "IPY_MODEL_7a4444bb015249ae9caa2b14c21fa0fd"
          }
        },
        "92345bd0ebed40f4bf0a9ac4aad2bc5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9344070d5d004c0fb5c0bdf22632e343": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_738b0850c1a4489a9147a63f3a587dd6",
            "max": 102491894,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9604ece7c2bb4e8ba8914d4430a72876",
            "value": 102491894
          }
        },
        "9604ece7c2bb4e8ba8914d4430a72876": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9718af278d2d45e99d1355cafc2c7518": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bdb4cdea53b429cad0e8c418fd7e715": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e5d67b0f3fb4baaa7254a102464057b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9718af278d2d45e99d1355cafc2c7518",
            "placeholder": "​",
            "style": "IPY_MODEL_cb11dac7ded84ad59f12a03b04660b3c",
            "value": "100%"
          }
        },
        "c4f0834d72224880b5a12217d95cb086": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d5fd07e913046a6b5445a791197a287",
            "placeholder": "​",
            "style": "IPY_MODEL_5a4441a529664fdfb5dc4d8de70b3421",
            "value": " 97.7M/97.7M [00:08&lt;00:00, 11.6MB/s]"
          }
        },
        "cb11dac7ded84ad59f12a03b04660b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb8e5c96ffea40e298a38db2b5a38ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2613e8b5e1e453db11090a1aa888799": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f750ac53345746ee8c0364b5f850a56d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2613e8b5e1e453db11090a1aa888799",
            "max": 167290877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9bdb4cdea53b429cad0e8c418fd7e715",
            "value": 167290877
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}